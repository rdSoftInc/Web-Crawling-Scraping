# Web-Crawling-Scraping

A web crawler & scraper, to crawl & scrap websites for relevant sites & data...

## Required Packages

run **npm install** command in the project folder terminal

## Command to run 

**npm start**


Tasks - âœ… - Completed | ðŸŸ§ - In Progress | ðŸ”² - Not Started 

#

âœ… Task 1  - **Rolstan** : Build a basic node js server & implement a web crawler function to find links & sub-links for a given url & store it in a json file  

âœ… Task 2  - **Robin & Giyosiddin** : Analyze the urls stored in prerequisites/horizon.json file & create pre-data fetch filter for processing required information. 

âœ… Task 3  - **Robin & Rolstan** : Create data model to support the required data for the base urls.

âœ… Task 4  - **Rolstan & Robin** : Build a web scraper to scrape data from the urls obtained from the web crawler.

âœ… Task 5  - **Giyosiddin** : Create a function to connect to a firebase database & data validation.

âœ… Task 6  - **Robin & Giyosiddin** : Connect the function of scraping data & data validation to store data in the firebase database.

âœ… Task 7  - **Rolstan** : Edit store-local.js function to make sure unique & only new urls are stored in the horizon.json file.

âœ… Task 8  - **Rolstan** : Crawl all the urls provided in urls.json file as a base url, so the above tasks can be performed for each base url.

âœ… Task 9  - **Rolstan** : Implement depth limit search for urls.

âœ… Task 10 - **Giyosiddin & Robin** : Modify Scrapper.js or Create a script just to upload the events.json data to db.

âœ… Task 11 - **Robin & Giyosiddin** : Report creation of the workflow.

âœ… Task 12 - **Giyosiddin** : Code Commenting & Optimization.

